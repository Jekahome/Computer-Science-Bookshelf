# Брайант Р. Э., О'Халларон Д. Р Компьютерные системы. Архитектура и программирование 2022

[веб-страница книги](http://csapp.cs.cmu.edu/)

[CS:APP3e Веб-дополнения](https://csapp.cs.cmu.edu/3e/waside.html)

[Сайт инструктора CS:APP3e](https://csapp.cs.cmu.edu/3e/instructors.html)

[Студенческий сайт CS:APP3e](https://csapp.cs.cmu.edu/3e/students.html)

![Carnegie Mellon University](img/covers/Carnegie_Mellon_University.jpg)
 
* [Глава 1. Экскурс в компьютерные системы](#Глава-1-Экскурс-в-компьютерные-системы)
    * [Процессор](#Процессор)
    * [Различные виды кеш-памяти](#Различные-виды-кеш-памяти)
    * [Конкуренция и параллелизм](#Конкуренция-и-параллелизм)
* [Глава 2. Представление информации и работа с ней](#Глава-2-Представление-информации-и-работа-с-ней)
    * [Хранение информации](#Хранение-информации)
* [Глава 3. Представление программ на машинном уровне](#Глава-3-Представление-программ-на-машинном-уровне)
  * [Программный код](#Программный-код)
  * [Машинный код](#Машинный-код)
* [Адресная арифметика AGU — Address Generation Unit](#Адресная-арифметика-agu--address-generation-unit)
* [Condition Codes, как работают if и while через флаги процессора](#condition-codes-как-работают-if-и-while-через-флаги-процессора)
* [Procedures (процедуры или функции)](#procedures-процедуры-или-функции)
* [Кэш-френдли код (Cache Locality)](#Кэш-френдли-код-cache-locality)
* [Cache Associativity. Уровень Кэша (Конфликт полок)](#cache-associativity-Уровень-Кэша-Конфликт-полок)
* []()
* []()
* []()
* []()
* []()
* []()
* []()

Оба автора, Рэндал Э. Брайант (Randal E. Bryant) и Дэвид Р. О'Халларон (David R. O'Hallaron), являются профессорами в Университете Карнеги-Меллона (Carnegie Mellon University, CMU).

Книга основана на курсе CMU: Учебник был разработан на основе курса "Introduction to Computer Systems" (Введение в компьютерные системы) (известного как 15-213), который они создали и преподавали в Школе компьютерных наук CMU.

Многие книги по компьютерным системам написаны для создателей таких систем и описывают, как скомпоновать оборудование или реализовать системное программное обеспечение, включая операционную систе­му, компилятор и сетевой интерфейс. Эта книга, напротив, написана для программиста и рассказывает, как прикладные программисты могут использовать свои знания о системах для создания более качественных программ.

Linux – одна из операционных систем, ведущих свою родо­словную от операцион­ной системы Unix, первоначально разработанной в Bell Laboratories. К другим членам этого класса операционных систем относятся Solaris, FreeBSD и MacOS X. В последние годы эти операционные системы сохраняли высокий уровень совместимости благодаря усилиям по стандартизации POSIX и Standard Unix Specification. То есть сведения, что приводятся в этой книге, почти напрямую применимы ко всем этим «Unix-подобным» операционным системам.


GNU («свободное» – в смысле «свобода слова», но не в смысле «бесплатное пиво»)

GСС – один из множества полезных инструментов, созданных в рамках проекта GNU (сокращенно от «GNU’s Not Unix» – «GNU – не Unix»). Проект GNU – это освобожденная от налогов благотворительная акция, основанная Ричардом Столлменом (Richard Stallman) в 1984 году с амбициозной целью разработать законченную Unix-подобную систему, исходный код которой не обременен ограничениями на его изменение и распространение.

---

> [!IMPORTANT]
> Важно, это не пересказ и не заметки по книге. Тут только то, что **мне** было интересно, то я и решил записать.
> Книга кладезь знаний, ее нужно читать полностью.
>

## Глава 1. Экскурс в компьютерные системы

### Процессор

Ассемблер — это почти прямое отражение модели ЦП. Ассемблер — это язык, в котором вы разговариваете с процессором на его родном, аппаратном языке, почти без переводчика.

Ассемблер не является «абстрактным» языком.

Ассемблер — читаемая человеком форма машинных инструкций, которые:
* читаются по адресу из PC,
* оперируют регистрами,
* используют ALU,
* обращаются к памяти,
* явно управляют переходами.

Поэтому его синтаксис — это буквально текстовое описание того, что аппаратно делает процессор.

**Центральный процессор** (ЦП; Central Processing Unit, CPU), или просто процессор, – это механизм, который интерпретирует (или выполняет) инст­рукции, хранящиеся в основной памяти. Его ядро составляет устройст­во памяти с емкостью в одно слово (или регистр) – счетчик команд (Program Counter, PC). В любой конкретный момент времени он хранит адрес некоторой машинной инструкции в основной памяти. Кажется, что процессор работает в соответствии с очень простой моделью выполнения инструкций, определяемой его архитектурным набором команд. Сначала процессор читает инструкцию из памяти по адресу в счетчике команд (PC), интерпретирует биты инструкции, выполняет простые операции, определяемые инструкцией, а затем обновляет значение счетчика, записывая в него адрес следующей инст­рукции, которая может размещаться за текущей или где-то в другом месте в памяти. 

Существует всего несколько таких простых операций, и все они связаны с обслуживанием основной памяти, блока регистров и арифметико-логичес­кого устройства (Arithmetic/Logic Unit, ALU). 

**Блок регистров** – небольшое запоминающее устройство из совокупности регистров, каждый из которых имеет свое уникальное имя и может хра- нить одно слово. 

**Устройство ALU** вычисляет новые значения данных и адресов. Назовем лишь несколько примеров простых операций, которые процессор может выполнить по требованию той или иной инструкции: 
* загрузка: копирует байт или слово из основной памяти в регистр, затирая при этом предыдущее содержимое этого регистра; 
* сохранение: копирует байт или слово из регистра в некоторую ячейку основной памяти, затирая при этом предыдущее содержимое этой ячейки; 
* выполнение арифметико-логической операции: копирует содержимое двух ре­ гистров в ALU, выполняет соответствующую операцию с этими словами и запо­ минает результат в одном из регистров, затирая при этом предыдущее содер­ жимое этого регистра; 
* переход: извлекает слово из самой инструкции и копирует его в счетчик команд (PC), затирая предыдущее его содержимое.

Любая осмысленная работа = сначала загрузить данные в регистры, потом работать с ними. 
И это сразу видно в ассемблере:
```asm
mov rax, [x]   ; загрузка из памяти → регистр
add rax, rbx  ; ALU работает только с регистрами
mov [y], rax  ; сохранение результата в память
```
 
Синтаксис отражает реальные шаги железа:
* load
* compute
* store

Ассемблер — это декларативное описание работы ALU и регистров, а не «алгоритм» в привычном смысле.

Типичная инструкция:
```asm
add rax, rbx
```

Это буквально описание микроархитектурного действия:
* взять содержимое rax
* взять содержимое rbx
* передать в ALU
* результат записать обратно в rax


Базовые операции ассемблера:
* load
* store
* arithmetic / logic
* jump

А все остальные возможности — это уже композиция этих примитивов ассемблерных операции.

---

### Различные виды кеш-памяти

Один из самых важных уроков этой книги заключается в том, что прикладные программисты, которые знают о наличии кеш-памяти, могут воспользоваться ею и увеличить производительность своих программ на порядок.

Машинные инструкции программы в начальный момент хранятся на диске. Когда производится загрузка программы, они копируются в основную память. По мере выполнения программы ее инструкции копируются из основной памяти в процессор.

Увеличить быстродействие процессора намного проще, чем заставить основную память работать быстрее. Чтобы уменьшить разрыв между процессором и основной памятью, создатели про-
цессоров включили в них небольшие быстродействующие устройства хранения, получившие название кеш-память.

Кеш L1 (его еще называют кешем первого уровня) внутри процессора может хранить десятки тысяч байт, и доступ к ним осуществляется почти так же быстро, как к регистрам. Еще больший объем имеет кеш L2 (кеш второго уровня) – он может вместить от сотен тысяч до миллионов байт. Этот кеш связан с процессором специальной шиной. Скорость доступа к кешу L2 в 5 раз ниже скорости доступа к кешу L1, и все равно она в 5–10 раз выше скорости доступа к основной памяти. Кеши L1 и L2 построены по технологии, известной как статическая память с произвольным доступом (Static Random Access Memory, SRAM). Более новые и более мощные системы имеют три уровня кешей: L1, L2 и L3.

Кэши встроены прямо в чип процессора. Чем ближе кэш к «мозгам», тем он быстрее, но меньше и дороже.

| Уровень | Скорость (примерно) | Размер (примерно) | Где находится |
| --- | --- | --- | --- |
| **Регистры** | 0 тактов (мгновенно) | пару сотен байт | Внутри ядра |
| **L1 Кэш** | ~4 такта | 32–64 КБ | Внутри каждого ядра |
| **L2 Кэш** | ~10–12 тактов | 256–512 КБ | Рядом с ядром |
| **L3 Кэш** | ~30–50 тактов | 8–64 МБ | Общий на весь процессор |
| **RAM** | **~200–300 тактов** | Гигабайты | Отдельная планка |


Идея поместить небольшое, зато более быстрое запоминающее устройство (кеш-память) между процессором и более емким, но с худшим быстродействием запоминающим устройством (основной памятью) оказалась весьма плодотворной. Фактически запоминающие устройства в любой вычислительной системе образуют иерархию.

По мере движения по этой иерархии сверху вниз устройства становятся все медленнее, объемнее, а стоимость хранения одного байта уменьшается. Регистры находятся на вершине иерархии, которая обозначается как уровень 0 (L0). Кеш-память занимает уровни с 1 по 3 (L1–L3). Основная память находится на уровне 4 (L4) и т. д. Основная идея иерархии памяти заключается в том, что память одного уровня служит кешем для следующего нижнего уровня. То есть блок регистров – это кеш для кеш-памяти L1. Кеши L1 и L2 служат кешами для кеш-памяти L2 и L3 соответственно.


![Carnegie Mellon University](img/CPU_Cache_vs_RAM_Speed.gif)

---

### Конкуренция и параллелизм

**Конкуренция на уровне потоков**

Основываясь на абстракции процессов, можно разрабатывать системы, в которых несколько программ выполняются одновременно, что приводит к конкуренции. Используя механизм потоков, можно даже запустить несколько потоков управления в рамках одного процесса.

Однопроцессорная система, конкурентное выполнение только моделируется – компьютер просто быст­ро переключался между выполняемыми процессами с загрузкой контекста.

Многопроцессорная система, все процессоры они управляются одним ядром операционной системы.

Многоядерные процессоры состоят из нескольких процессоров (называемых «ядрами»), интегрированных на один кристалл. Имеют в одной микросхеме четыре ядра, каждое со своими кешами L1 и L2, причем каждый кеш L1 разделен на две части: одна предназначена для хранения недавно выбиравшихся инструкций, а другая – данных. Ядра совместно используют кеш-память более высокого уровня (L3), а также интерфейс с основной памятью.

Гиперпоточность, которую иногда называют одновременной многопоточностью, – это технология, позволяющая одному процессору выполнять сразу несколько потоков управления. Это предполагает наличие нескольких копий определенных аппаратных средств процессора, таких как счетчики инструкций и блоки регистров, при этом другие аппаратные компоненты, такие как блок арифметических операций с плавающей точкой, наличествуют в единст­венном числе.

**Параллелизм на уровне инструкций**

Современные процессоры могут выполнять несколько инструкций одновременно. 
Использование конвейерной обработки, в которой дейст­вия, необходимые для выполнения инструкции, разделены на этапы, а аппаратное обеспечение процессора организовано в виде последовательности стадий, каждая из которых выполняет один из этапов. Стадии могут работать параллельно, выполняя разные части разных инструкций. Для поддержания скорости выполнения, близкой к 1 инструкции на такт, не требуется ничего особенно сложного. Процессоры, которые могут выполнять более одной инструкции за такт, называют суперскалярными. 
Прикладные программисты могут использовать эту модель для прогнозирования производительности своих программ, а затем писать программы так, чтобы сгенерированный код достигал более высокой степени параллелизма на уровне инструкций и, следовательно, работал быстрее.

**Одиночный поток команд, множественный поток данных**

На самом низком уровне многие современные процессоры имеют специальное оборудование, позволяющее одной инструкции параллельно выполнять несколько операций. Этот режим известен как одиночный поток команд, множественный поток данных (Single-Instruction, Multiple-Data, SIMD). Например, в последних поколениях процессоров Intel и AMD есть инструкции, которые могут параллельно складывать 8 пар чисел с плавающей точкой одинарной точности (тип данных float в языке C).

Эти инструкции SIMD предоставляются в основном для ускорения приложений, обрабатывающих изображения, звук и видео. Некоторые компиляторы пытаются автоматически использовать параллелизм этого вида в программах на C, но все же более надежным методом является разработка программ с использованием специальных типов векторных данных, поддерживаемых компиляторами, такими как GCC.

### Итоги

Компьютерные системы состоят из аппаратных и программных средств, которые взаимо­действуют с целью выполнения прикладных программ. Информация внутри компьютера представлена в виде групп битов, которые интерпретируются в зависимости от контекста. Программы транслируются другими программами в различные формы. Сначала они представлены в виде исходного текста ASCII, затем преобразуются компиляторами и компоновщиками в выполняемые файлы.

Процессоры читают и интерпретируют двоичные инструкции, находящиеся в основной памяти. Поскольку большую часть времени компьютеры тратят на копирование данных между основной памятью, устройствами ввода/вывода и регистрами процессора, память системы образует некоторую иерархию, на вершине которой находятся регистры процессора, далее следуют несколько уровней аппаратной кеш-памяти, затем основная DRAM-память и дисковая память. Чем выше находится устройство памяти в иерархии, тем выше его быстродействие и стоимость в пересчете на один бит. Кроме того, устройства памяти, находящиеся выше в иерархии, служат кешем для устройств памяти, находящихся ниже. Программисты могут опти­мизировать производительность своих программ на языке С, изучив и воспользовавшись особенностями иерархии памяти.

Ядро операционной системы играет роль посредника между прикладными программами и аппаратными средствами. Оно реализует три фундаментальные абстракции:
1) файлы, абстрагирующие устройства ввода/вывода;
2) виртуальную память, абстрагирующую как основную память, так и дисковую;
3) процессы, абстрагирующие процессоры, основную память и устройства ввода/вывода. 

Наконец, сети дают компьютерным системам возможность обмениваться данными между собой. С точки зрения конкретной системы, сеть есть не что иное, как устройство ввода/вывода.

---

## Глава 2. Представление информации и работа с ней

### Хранение информации

#### Размеры данных

Каждый компьютер имеет размер машинного слова, указывающий номинальный размер указателя. Поскольку виртуальные адреса кодируются такими словами, то наиболее важным системным параметром, определяемым размером слова, является максимальный размер виртуального адресного пространства. То есть для машины с размером слова в w бит диапазон виртуальных адресов охватывает от 0 до $2^w$ – 1, обеспечивая программе дос­туп максимум к $2^w$ байт.

В настоящее время наблюдается масштабный переход от машин с размером слова в 32 бита к машинам с размером слова в 64 бита.

**Почему 32-битная система ограничена ~4 ГБ?**

- **Размер указателя** (адреса) = 32 бита (4 байта).
- **Каждое значение указателя** — это число от `0x00000000` до `0xFFFFFFFF` (в шестнадцатеричной) или от `0` до `2³² − 1`.
- **2³² = 4 294 967 296** возможных адресов.

Каждому байту памяти присваивается свой уникальный адрес (байтовая адресация), поэтому в 32-битной системе максимально адресумая ячейка памяти в **виртуальном адресном пространстве** процесса ограничена числом `4_294_967_296 = 2³²− 1 = 0xFFFFFFFF = 4 ГБ`

Для 64-битной системы, количество адресов $2^{64}$ байт = `16_000_000_000 ГБ = 15_625_000 ТБ = 16 Эбайт`. 

Но реально в современных 64-битных процессорах (x86_64, ARM64) используются не все 64 бита для адресации: 
* Стандартный режим (48 бит): `262_144 ГБ = 256 ТБ`
* Расширенный режим (57 бит с 5-level paging): `134_217_728 ГБ`

Для языка C:
* Тип данных long в 32-разрядных программах обычно имеет размер 4 байта, а в 64-разрядных – 8 байт.
* Тип `void*` (указатель) в 32-разрядных программах 4 байта (32 бита), а в 64-разрядных – 8 байт (64 бита).
* Тип size_t в 32-разрядных программах 4 байта (32 бита), а в 64-разрядных – 8 байт (64 бита)

Правильный подход для переносимого кода:
```c
#include <stdint.h>

// Использовать фиксированные типы:
int8_t  -    // 8 bit (1 byte) Всегда 8 бит, тоже самое signed char  
int16_t -    // 16 bit (2 byte) Всегда 16 бит 
int32_t -    // Всегда 32 бита
int64_t -    // Всегда 64 бита
uintptr_t -  // Беззнаковый тип, вмещающий указатель
size_t    -  // Для размеров объектов (меняется с разрядностью)

```

#### Адресация и порядок следования байтов

Для программных объектов, занимающих несколько байтов, необходимо установить два правила: каков будет адрес объекта и как должны располагаться байты в памяти. 

Практически во всех машинах такие объекты хранятся в виде непрерывных последовательностей байтов, а адресом многобайтного объекта служит наименьший адрес ячейки памяти. Например, предположим, что переменная x типа `int` имеет адрес `0x100`, т.е. выражение взятия адреса `&x` вернет `0x100`. Тогда четыре байта, составляющих значение переменной `x`, будут храниться в ячейках памяти `0x100, 0x101, 0x102 и 0x103`.
 
Как должны располагаться байты в памяти. 
* Первое правило: порядок, когда первым следует наименьший значащий байт, называется обратным, или остроконечным (little endian).
* Второе правило: порядок, когда первым следует наибольший значащий байт, называется прямым, или тупоконечным (big endian).

Порядок байтов фиксируется с выбором конкретной **операционной системы**.
 
**Little-endian (LE)**
* **Наименее значимый байт** идёт **первым** (по меньшему адресу).
* Пример: `0x12345678` хранится как `78 56 34 12`.
* Доминирование архитектуры x86 — Intel выбрала LE, и теперь это стандарт де-факто для десктопа.
* Так делают почти все современные процессоры (Intel x86, AMD64, ARM в режиме по умолчанию). Это логично для схем и кода, удобнее считать и обрабатывать данные.
* Простота приведения типов — `int16_t x = 0x1234; → int8_t y = (int8_t)x;` даст `0x34` без сдвига адреса.
* Эффективность арифметики — сложение/вычитание начинается с младших байтов, можно не знать длину числа.

**Big-endian (BE)**
* **Наиболее значимый байт** идёт **первым** (по меньшему адресу).
* Пример: `0x12345678` хранится как `12 34 56 78`.
* Человеку этот способ привычнее, потому что мы пишем числа "от старшего к младшему".
* Простота отладки — дамп памяти читается как шестнадцатеричное число.
* В сетевых протоколах (TCP/IP) стандарт принят именно BE (его ещё называют *network byte order*).


**Почему это важно**
* Если два компьютера обмениваются числами напрямую в байтах, они должны договориться о порядке байт.
* Если вы записываете числа в бинарный файл, порядок байт должен быть фиксирован и понятен для всех, кто будет его читать.
* Ошибка с порядком байт может "перевернуть" значения:
  * `0x12345678` (305419896) на LE выглядит как `78 56 34 12` (2018915346 на BE, если интерпретировать не тем способом).


**Текстовые данные менее зависимы от платформы, нежели двоичные.**

**Текстовые данные (например, JSON, XML, CSV, plain text):**
- Платформенно-независимы — используют только ASCII/Unicode символы
- Портативны — одинаково читаются на x86, ARM, big-endian, little-endian
- Отлаживаемы — можно открыть в любом текстовом редакторе

**Двоичные данные (бинарные файлы):**

Зависят от:
- Endianness (порядок байтов)
- Размер типов (`int` = 4 или 8 байт?)
- Выравнивание структур (padding)
- Представление чисел с плавающей точкой

...

> [!INFO]
> далее в книге идет речь про особенности представления чисел в бинарном виде. 
> Особенности при операциях с вещественными числами и как вещественные числа хранятся в памяти.
> * Округление к ближайшему четному (Round to Even)
> * "Дыры" в представлении вещественных числах компьютером
> * Представление значений с плавающей точкой в стандарте IEEE
> * Почему максимальное отрицательное число не может быть представленно беззнаковым типом того разряда...
> Особенности при операциях с целыми знаковыми и т.д.. 
> Ситуации переполнения типа, битовые сдвиги ...
>
> И про то что компилятор может не предупредить о возникновении переполнения типа ...
>

---

## Глава 3. Представление программ на машинном уровне

Свой технический обзор мы начнем с того, что покажем связь между исходным кодом на языке С, ассемблерным и объектным кодами. Затем перейдем к исследованию особенностей архитектуры x86-64, начав с представления данных, манипулирования ими и реализации управления.

Зачем же тратить время на изучение машинного кода:
* какими возможностями обладает компилятор, и выявить неэффективные фрагменты программы.


Трансляция выполняется в четыре этапа. Совокупность программ, выполняющих эти четыре этапа (препроцессор, компилятор, ассемблер и компоновщик), называется системой компиляции.

Последовательность работы GCC (GNU Compiler Collection):

**1. Препроцессинг (Preprocessing)**

Инструмент: `cpp`
Что происходит: Работа с текстом программы.

* Удаляются комментарии.
* Подставляется содержимое заголовочных файлов (`#include`).
* Разворачиваются макросы (`#define`).
* Результат: «Чистый» код на Си (обычно файл с расширением `.i`).

**2. Компиляция (Compilation)**

Инструмент: `cc1`
Что происходит: Самый сложный этап. Компилятор анализирует синтаксис, проверяет ошибки и переводит код с языка Си на язык ассемблера.

* Результат: Текстовый файл с инструкциями ассемблера (расширение `.s`).
* *В вашем тексте этот этап назван генерацией ассемблерного кода.*

**3. Ассемблирование (Assembly)**

Инструмент: `as`
Что происходит: Перевод текстовых команд ассемблера в машинный код (нули и единицы), который понимает процессор.

* Результат: Объектный файл (расширение `.o` или `.obj`). Это уже машинный код, но его еще нельзя запустить, так как в нем не прописаны адреса внешних функций (например, `printf`).

**4. Компоновка / Линковка (Linking)**

Инструмент: `ld`
Что происходит: Сборка всех объектных файлов и системных библиотек в один целое. Линкер «сшивает» вызовы функций с их реальными адресами в памяти.

* Результат: Исполняемый файл (например, `a.out`, `main.exe` или ELF).

---

### Программный код

Прямая компиляция всех файлов.

Вместо того чтобы вводить четыре команды для каждого файла:

```
gcc -c p1.c

gcc -c p2.c

gcc -o p p1.o p2.o

```

Запускает всю цепочку преобразований одним махом для нескольких файлов сразу.

```
gcc -Og -o p p1.c p2.c
```

Флаг оптимизации **-Og** - оптимизирует, но бережет структуру программы, специально для удобства отладки (GDB)

Когда мы смотрим на результат оптимизации **-Og**, мы можем увидеть, что компилятор, например, не смог соптимизировать наш цикл. Это сигнал: «вы написали код так запутанно, что даже компилятор боится его трогать». Если мы поможем компилятору на уровне **-Og** (сделаешь код чище), то на уровне **-O3** он выдаст еще более впечатляющий результат.

---

### Машинный код

File mstore.c:
```c
long mult2(long, long);
void multstore(long x, long y, long *dest) {
    long t = mult2(x, y);
    *dest = t;
}
```

Чтобы увидеть соответствующий ассемблерный код формата AT&T (по умолчанию), сгенерированный компилятором С, добавим в командную строку параметр -S:
```
# создание ассемблерного представления кода из mstore.c
gcc -Og -S mstore.c
```

По этой команде GCC запустит компилятор, сгенерирует ассемблерный код, сохранит его в файле mstore.s и на этом остановится. (В обычной ситуации он далее вызывал бы ассемблер, чтобы тот сгенерировал файл с объектным кодом.)

```
# в стандартном предтавлении ассемблерного кода формата AT&T 
$ — это число, а % — регистр. И порядок обратный: "откуда -> куда"
```

File mstore.s:
```bash
	.file	"mstore.c"
	.text
	.globl	multstore
	.type	multstore, @function
multstore:
.LFB0:
	.cfi_startproc
	endbr64
	pushq	%rbx
	.cfi_def_cfa_offset 16
	.cfi_offset 3, -16
	movq	%rdx, %rbx
	call	mult2@PLT
	movq	%rax, (%rbx)
	popq	%rbx
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE0:
	.size	multstore, .-multstore
	.ident	"GCC: (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0"
	.section	.note.GNU-stack,"",@progbits
	.section	.note.gnu.property,"a"
	.align 8
	.long	1f - 0f
	.long	4f - 1f
	.long	5
0:
	.string	"GNU"
1:
	.align 8
	.long	0xc0000002
	.long	3f - 2f
2:
	.long	0x3
3:
	.align 8
4:

```

<details>

<summary>Для ассемблерного представления в формате Intel,Microsoft</summary>

```
# создание ассемблерного представления кода из mstore.c
gcc -Og -S -masm=intel mstore.c
```

File mstore.s:
```bash
	.file	"mstore.c"
	.intel_syntax noprefix
	.text
	.globl	multstore
	.type	multstore, @function
multstore:
.LFB0:
	.cfi_startproc
	endbr64
	push	rbx
	.cfi_def_cfa_offset 16
	.cfi_offset 3, -16
	mov	rbx, rdx
	call	mult2@PLT
	mov	QWORD PTR [rbx], rax
	pop	rbx
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE0:
	.size	multstore, .-multstore
	.ident	"GCC: (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0"
	.section	.note.GNU-stack,"",@progbits
	.section	.note.gnu.property,"a"
	.align 8
	.long	1f - 0f
	.long	4f - 1f
	.long	5
0:
	.string	"GNU"
1:
	.align 8
	.long	0xc0000002
	.long	3f - 2f
2:
	.long	0x3
3:
	.align 8
4:

```

</details>

Чтобы увидеть двоичный объектный код (например, в файле mstore), можно воспользоваться дизассемблером, который покажет, что программный код процедуры содержит 14 байт.
```
# создание обьектного файла mstore.o
gcc -Og -c mstore.c

# запустить отладчик GNU GDB
gdb mstore.o
```

output:
```
# вывести 18 байт начиная с метки multstore
(gdb) x/18xb multstore
0x0 <multstore>:        0xf3    0x0f    0x1e    0xfa    0x53    0x48    0x89    0xd3
0x8 <multstore+8>:      0xe8    0x00    0x00    0x00    0x00    0x48    0x89    0x03
0x10 <multstore+16>:    0x5b    0xc3
(gdb) q
```

Для исследования содержимого файлов с машинным кодом особенно ценным может оказаться класс программ, известных как дизассемблеры. Эти программы генерируют из машинного кода программный код на языке ассемблера.

```
objdump -d mstore.o
```

output:
```
mstore.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 <multstore>:

Смещение | Байты                 | Эквивалент на языке ассемблера
   0:     f3 0f 1e fa             endbr64
   4:     53                      push   %rbx
   5:     48 89 d3                mov    %rdx,%rbx
   8:     e8 00 00 00 00          call   d <multstore+0xd>
   d:     48 89 03                mov    %rax,(%rbx)
  10:     5b                      pop    %rbx
  11:     c3                      ret
```

Чтобы получить фактический выполняемый код, файлы с объектным кодом необходимо обработать компоновщиком, при этом один из этих файлов обязательно должен содержать функцию main. Предположим, что в файле main.с определена следующая функция:

File main.c:
```c
#include <stdio.h>
void multstore(long, long, long *);
int main() {
    long d;
    multstore(2, 3, &d);
    printf("2 * 3 --> %ld\n", d);
    return 0;
}
long mult2(long a, long b) {
    long s = a * b;
    return s;
}
```

В таком случае мы можем сгенерировать выполняемый файл prog программы следую­щим образом:
```
gcc -Og -o prog main.c mstore.c
```

Размер файла prog вырос до 8655 байт, потому что он содержит не только машин-
ный код двух процедур, но и информацию, используемую для запус­ка и завершения
программы, а также для взаимодействия с операционной систе­мой.

Файл prog можно дизассемблировать:
```
objdump -d prog
```

Результат дизассемблирования функции multstore в двоичном файле prog
```
00000000000011d8 <multstore>:
    11d8:       f3 0f 1e fa             endbr64
    11dc:       53                      push   %rbx
    11dd:       48 89 d3                mov    %rdx,%rbx
    11e0:       e8 e7 ff ff ff          call   11cc <mult2>
    11e5:       48 89 03                mov    %rax,(%rbx)
    11e8:       5b                      pop    %rbx
    11e9:       c3                      ret

```

Этот код практически идентичен полученному при дизассемблировании файла mstore.o. Главное отличие – другие адреса в колонке слева. Компоновщик изменил мес­тоположение этого кода, в результате чего адреса инструкций изменились. Второе отличие – компоновщик заполнил адрес вызываемой функции mult2 в инструкции callq. Одна из задач компоновщика – сопоставить вызовы функций с их местоположениями.

Вот как выглядит версия нашего примера с комментариями:
```
 push   %rbx         ; Сохранить %rbx на стеке
 mov    %rdx,%rbx    ; Скопировать dest в %rbx
 call   11cc <mult2> ; Вызвать mult2(x, y)
 mov    %rax,(%rbx)  ; Сохранить результат по адресу *dest
 pop    %rbx         ; Восстановить %rbx
 ret                 ; Вернуть управление
```

В некоторых ситуациях программистам приходится прибегать к ассемблерному коду, чтобы получить доступ к низкоуровневым возможностям машины. 

**Один из способов получить такой доступ** – написать группу функций на ассемблере и объединить их с функциями на C на этапе компоновки. Напи­сать
функцию целиком на языке ассемблера, поместить ее в отдельный файл и позволить
ассемблеру и компоновщику объединить ее с программным кодом на C. 

Мы разделяем логику: алгоритм пишем на Си, а «грязную» работу с железом — в отдельном .s файле.

Файл с кодом на ассемблере math_tools.s:
```asm
# math_tools.s
.globl asm_add           # Делаем имя функции видимым для линкера

asm_add:
    # В x86-64 (Linux) первые два аргумента приходят в регистрах:
    # edi — первое число
    # esi — второе число

    addl %esi, %edi      # Складываем: edi = edi + esi
    movl %edi, %eax      # Результат функции всегда должен лежать в eax
    ret                  # Возврат в вызывающую функцию
```

Инструкция movl означает (`mov` + `l`) перемещение двойного слова:
* `b` - 1 байт char
* `w` - 2 байта short слово
* `l` - 4 байта int двойное слово
* `q` - 8 байт long или char* четверное слово
* `s` - 4 байта float одинарной точности
* `l` - 8 байт double двойное слово

Файл main.c:
```c
#include <stdio.h>

// Объявляем внешнюю функцию, написанную на ассемблере
extern int asm_add(int a, int b);

int main() {
    int x = 10;
    int y = 20;
    
    int result = asm_add(x, y);
    
    printf("Результат из ассемблера: %d\n", result);
    return 0;
}
```

Сборка:
* Компилируем Си: `gcc -c main.c -o main.o`
* Ассемблируем Асм: `gcc -c math_tools.s -o math_tools.o`
* Линкуем всё вместе: `gcc main.o math_tools.o -o my_app`

В должны строго соблюдать Calling Convention (соглашение о вызовах). Если вы решите забрать аргументы не из тех регистров (например, из ebx вместо edi), программа получит мусор вместо чисел. Для x86-64 в Linux порядок такой: rdi, rsi, rdx, rcx, r8, r9.
 

**Второй способ (Inline Assembly)** – использовать поддержку GCC для встраивания ассемблерного кода непосредственно в программы на C. Использовать поддержку встраивания ассемблерного кода, имеющуюся в GCC, позволяющую с
помощью директивы asm вставлять короткие фрагменты кода на ассемблере прямо в
программу на C. Преимущество этого подхода в том, что он сводит к минимуму объем
машинно зависимого кода.

Вам не нужно знать Calling Convention: Вам не обязательно помнить, что первый аргумент должен быть в rdi. Вы просто говорите компилятору: «Мне нужно это число в любом свободном регистре», и GCC сам выберет лучший вариант.

Файл main.c:
```c
#include <stdio.h>

int main() {
    int x = 10;
    int y = 20;
    int result;

    // Вставка ассемблерного кода прямо в Си
    __asm__ (
        "addl %%ebx, %%eax;"  // Сама команда: eax = eax + ebx
        : "=a" (result)       // Выходные данные: буква 'a' означает регистр eax. Результат будет в eax, запиши его в 'result'
        : "a" (x), "b" (y)    // Входные данные: буква 'b' означает регистр ebx. Положи 'x' в eax, а 'y' в ebx
    );

    printf("Результат из inline-вставки: %d\n", result);
    return 0;
}
```

Сборка:
```
gcc -o main main.c
```
 
Устройство регистров:

![x86-64 Integer registers](img/x86-64_Integer_registers.png)

Как показывают вложенные прямоугольники, инструкции могут работать с данными разного размера, хранящимися в младших байтах 16 регистров. Операции с отдельными байтами манипулируют младшими байтами, 16-разрядные операции – двумя младшими байтами, 32-разрядные операции – четырьмя младшими байтами, 64-разрядные операции – целыми регист­рами.

---

### Адресная арифметика AGU — Address Generation Unit
(правильно располагать данные в RAM)

> [!IMPORTANT]
> Почему это важно знать?

**Как x86-64 за один такт вычисляет адрес в памяти.**

Должно соблюдаться условие:
* адрес начала массива должен быть кратен размеру данных. Если массив из int (4 байта), то адрес начала должен делиться на 4
* размер данных элементов массива должен быть степенью двойки т.е. строго (1, 2, 4 и 8), если размер больше даже если 16, 32 все равно в один такт не получится.
* размер структуры должен быть выровнен и поля структуры должны быть уложены в чанки по 8 байт. 

В железе (в блоке AGU) умножение на произвольное число (например, на 7 или 13) — это медленная операция, требующая полноценного умножителя. А умножение на 1, 2, 4 и 8 делается простым битовым сдвигом влево (на 0, 1, 2 или 3 бита).  

Вот формула того, как процессор вычисляет адреса элементов массива и структур. Процессор x86-64 выполняет эту формулу аппаратно внутри одного блока (AGU — Address Generation Unit). Это значит, что сложение и умножение в этой формуле происходят бесплатно с точки зрения времени. Он вычисляет весь адрес целиком за **один** такт.

`Addr = D + Reg[Rb] + Reg[Ri] * S`

* **D** (Displacement): Смещение. Удобно для доступа к полям в структурах (struct)
* **Rb** (Base): Базовый регистр. Начало массива или объекта
* **Ri** (Index): Индексный регистр. Номер элемента в массиве  
* **S** (Scale): Множитель (только 1, 2, 4 или 8). Размер типа данных (int — 4 байта, double или указатель — 8 байт)

Пример:

```
int arr[6] = {1,2,3,4,5,6};

int x = arr[5];// Компилятор превратит вычисление адреса элемента массива в одну инструкцию: (%rdx, %rcx, 4)
```
* %rdx — адрес начала массива
* %rcx — твой индекс 
* 4 — потому что int занимает 4 байта


Допустим:
* **D** (Displacement) смещение равно 0
* **Rb** (Base) адрес начала массива %rdx равен 1000
* **Ri** (Index) равен 5
* **S** (Scale) размер типа данных для int 4

```
Addr = D + Reg[Rb] + Reg[Ri] * S = 0 + 1000 + 5 * 4 = 1020

```
Процессор мгновенно вычисляет адрес 1020 за один такт в AGU, обращается к памяти и забирает оттуда число 6.


Почему индексы массивов начинаются с нуля, если индекс Ri = 0, то: `Addr = Base + 0 * Scale = Base` т.е. адрес самого массива.

**Если у нас массив содержит тип данных размер которых не кратен степени двойки, например, не выровненная структура с двумя полями double и int = 12 байт, процессор уже не сможет вычислить адрес за один такт в AGU с помощью формулы `D(Rb, Ri, S)`**


**Выравнивание (Alignment) — это вторая часть проблемы**

Даже если мы вычислили адрес правильно, в дело вступает шина данных. Процессор тянет данные из памяти кусками по 8 байт (64 бита). Эти куски «нарезаны» в памяти строго по адресам, кратным 8.

Если наш double лежит по адресу 0x08, он идеально попадает в один «заход» процессора.

Если наш double из-за кривого размера структуры оказался на адресе `0x05`, он «размазан» между двумя блоками памяти. Процессору нужно два раза сходить в память, достать два куска, отрезать лишнее и склеить остаток.

---

### Condition Codes, как работают if и while через флаги процессора
(Минимизация прыжков т.е. if, while, for, switch. Писать логику так, чтобы процессор не захлебывался)

**Флаги состояния (Condition Codes)**

В процессоре есть специальный регистр флагов (EFLAGS). Почти любая арифметическая операция (сложение, вычитание и т.д.) меняет эти флаги как «побочный эффект».

* **ZF** (Zero Flag): Установится в 1, если результат операции был 0. (Идеально для `if (a == b)`, так как a - b = 0)
* **SF** (Sign Flag): Установится в 1, если результат отрицательный. (Для проверок `a < b`)
* **CF** (Carry Flag): Флаг переноса (для беззнаковых чисел)
* **OF** (Overflow Flag): Флаг переполнения (для чисел со знаком)

**Команды сравнения (cmp и test)**
* **cmp b, a**: Вычисляет `a - b`. Результат выкидывает, но выставляет флаги (**ZF, SF** и т.д.)
* **test b, a**: Вычисляет `a & b` (побитовое И). Тоже выкидывает результат, но выставляет флаги

**Прыжки (Jumps)**

Процессор читает флаги и, если условие совпадает, меняет свой Instruction Pointer (указатель на следующую строку кода)
* **je** (Jump if Equal): Прыгнуть, если флаг ZF=1.
* **jne** (Jump if Not Equal): Прыгнуть, если ZF=0.
* **jl** (Jump if Less): Прыгнуть, если результат был меньше нуля.

Прыжки (условные переходы) тормозят конвейер (pipeline) вычисления процессора. Современный процессор загружает в конвейер десятки инструкций наперед, а `jmp` ломает эту цепочку.
* Для безусловного jmp: Процессор внезапно понимает, что всё, что он уже успел загрузить в конвейер «после» прыжка — это мусор. Ему нужно всё выкинуть, пойти по новому адресу и начать загружать инструкции заново. Это пустые такты ожидания.
* Для условного перехода (je, jg): Тут еще хуже. Процессор не знает, прыгнет он или нет, пока не выполнит сравнение. Чтобы не стоять на месте, он гадает (Branch Prediction). Если угадал — молодец. Если ошибся — «катастрофа»: конвейер полностью очищается, все вычисления обнуляются, и процессор начинает работать с нуля по другой ветке.
 

Современные процессоры суперскалярны (Superscalar execution) они имеют несколько конвейеров (pipeline) работающих параллельно, которые загружены теми инструкциями кода который предсказал (Branch Predictor), когда предсказатель ошибается (Branch Misprediction), процессор выкидывает все результаты из всех параллельных линий и полностью очищает конвейер. Если есть работа которая не зависит от предыдущей работы то это будет просчитано в одном из конвейеров заранее. 
Например независимые данные будут просчитаны параллельно

```
a = b + c;
d = e + f;
```

В таком случае конвейер будет стоять и ждать, пока первый закончит работу. Это называется Data Dependency (зависимость по данным):

```
a = b + c;
d = a + f; // d зависит от результата первой строки
```

**Например, развертывание циклов (Loop Unrolling).**

Вместо того чтобы считать по одному числу в цикле:

```
for (i = 0; i < 100; i++) {
    sum += a[i]; // Каждая итерация зависит от предыдущей (sum)
}
```

Чтобы задействовать параллельные конвейеры:

```
for (i = 0; i < 100; i += 2) {
    sum1 += a[i];     // Конвейер 1
    sum2 += a[i + 1]; // Конвейер 2 (не зависит от sum1)
}
total_sum = sum1 + sum2;
```

Это будет работать почти в два раза быстрее, потому что мы дали процессору возможность загрузить две параллельные линии одновременно. Мы убрали «зависимость по данным» (Data Dependency) на уровне одной итерации.



Совсем без прыжков программу не напишешь. Поэтому инженеры придумали, как сделать их менее болезненными:
* Loop Unrolling (Развертывание цикла): Вместо того чтобы делать цикл на 4 итерации с 4 прыжками:

  ```
  for(int i=0; i<4; i++) a[i] = 0;

  Компилятор делает так:
  a[0] = 0; a[1] = 0; a[2] = 0; a[3] = 0;// Прыжков — ноль. Конвейер забит полезной работой.
  ```
* Conditional Move (cmov): вместо «прыгни, если больше», процессор просто говорит: «Вычисли оба варианта, а в конце я просто перепишу результат в зависимости от флага». Прыжка нет физически, конвейер идет ровно. Это можно реализовать заменой if на тернарный оператор.


> [!IMPORTANT]
> Почему это важно знать?

* **Предсказание переходов (Branch Prediction)**: Процессор пытается угадать, прыгнет он или нет, еще до того, как выполнит cmp. Если он ошибается, он теряет кучу тактов на очистку конвейера.
* **Условные передачи (cmov)**: Современные компиляторы иногда заменяют `if` на специальные инструкции, которые вообще не требуют прыжков, что делает код невероятно быстрым.

**Предсказание переходов (Branch Prediction)**

Современный процессор — это конвейер. Он начинает выполнять следующие команды еще до того, как закончил текущую. Когда он видит `if (condition)`, он не ждет результата сравнения, а угадывает, куда пойдет код, и начинает выполнять ту ветку заранее.

Это называется спекулятивное выполнение (speculative execution). Процессор — это своего рода игрок на ставках: он ставит на один из исходов `if`, чтобы не простаивать. Если ставка не сыграла, он делает «откат» (pipeline flush), что стоит примерно 15–20 тактов работы.

Вот основные стратегии, как писать код, чтобы процессор «угадывал» чаще:

**1. Сортировка данных**

Если мы обрабатываем массив в цикле и внутри есть `if`, процессор будет угадывать почти идеально, если данные отсортированы.

**2. Избавление от веток (Branchless Programming)**

Если можно заменить `if` математикой — сделайте это.

```
Пример: Найти сумму всех элементов массива, которые больше 10.

С ветвлением:
if (a[i] > 10) sum += a[i];

Без ветвления (математически):
sum += (a[i] > 10) * a[i];

итог: у процессора него нет выбора пути, а значит, нет риска ошибки. 
Нет прыжка — нет риска ошибиться в предсказании — код работает быстрее.
```

**3. Использование тернарного оператора (cmov)**

Компиляторы часто превращают простые тернарные операторы в инструкцию `cmov` (Conditional Move)

```
int max = (a > b) ? a : b;
итог: Нет прыжка — нет риска ошибиться в предсказании — код работает быстрее.
```

**4. Избегайте switch с кучей мелких кейсов**

Если в switch 20 разных вариантов, которые выпадают случайно, предсказатель переходов просто «сойдет с ума». В таких случаях лучше либо структурировать данные иначе, либо использовать таблицы переходов (которые компилятор сам создаст, если кейсы идут плотно по порядку).

**5. Пишите простые условия выхода из цикла**. 

Чем проще условие в while, тем легче компилятору превратить его в эффективный do-while с одним прыжком.

**6. Вероятные и невероятные ветки (Likely/Unlikely)**

Если вы точно знаете, что одно условие срабатывает в 99% случаев (например, проверка на ошибку, которой почти никогда не бывает), вы можете подсказать компилятору.

В современных компиляторах (GCC/Clang) есть макросы:


```c
if (__builtin_expect(ptr == NULL, 0)) { // говорим, что NULL — это почти невозможно

// код обработки редкой ошибки

}
```

Компилятор переставит блоки кода в ассемблере так, чтобы основная ветка шла «напролом» без прыжков, а редкая — была в стороне.

---

### Procedures (процедуры или функции)
(Главный враг кэша — «Прыжки»)

Почему программисты используют **inline функции**? — они просят компилятор не делать «телепортацию», а просто вставить код функции прямо в место вызова, превращая это в обычную линейную последовательность команд без всяких стеков. Но у него есть обратная сторона: если функция огромная и мы «инлайним» её в 100 местах, размер нашего исполняемого файла (.exe или .bin) раздувается. Это может привести к тому, что код перестанет влезать в L1-кэш инструкций процессора, и программа, как ни парадоксально, станет работать медленнее. Поэтому компиляторы иногда игнорируют просьбу об inline, если видят, что это навредит.

> [!IMPORTANT]
> Почему это важно знать?

Вызов функции — это самый дорогой прыжок. Нужно сохранить адрес возврата (Return Address), очистить/сохранить регистры и, возможно, выделить еще память в стеке под локальные данные в функции.

Для этого call прыжка процессор использует струтуру Stack заполняя ее последовательно состоянием программы, что бы при возврате ret снова восстановить то состояние которое было до прыжка.

>
> Стек в x86-64 — это область памяти, которая растет вниз (от больших адресов к меньшим). За него отвечает регистр %rsp (Stack Pointer).
>
> Передача аргументов (Секрет скорости x86-64). В современной x86-64 первые **6 аргументов** передаются через регистры (%rdi, %rsi, %rdx, %rcx, %r8, %r9).
>
> Локальные переменные. Если внутри функции не хватает регистров, мы «откусываем» кусок памяти у стека, просто уменьшая значение %rsp. Это и есть «рюкзак» памяти стека (Stack Frame), где лежат локальные переменные.
>
> Безопасность (Buffer Overflow): Если мы запишем в локальный массив больше данных, чем он вмещает, мы можем затереть тот самый Return Address. Тогда, когда функция будет возвращаться ret, она прыгнет не назад в код, а по адресу, который подсунул хакер.
>

---

### Кэш-френдли код (Cache Locality) 


**Почему огромные двумерные массивы лучше обходить «по строкам», а не «по столбцам»**

```c
void func(int arr[8][5]) // 8 рядов (строк) и 5 столбцов (колонок)

```

Память хранит данные **линейно**.

> [!IMPORTANT]
> **Почему это важно знать?**


* Строка = Ряд (Row) — Друзья кэша.
* Колонка = Столбец (Column) — Враги кэша (если идти только по ним).


Поскольку данные двумерного массива лежат по строкам (Row-major order), т.е. **линейно**, процессор читает их эффективно только тогда, когда мы идем по ним подряд.  

Процессор высчитывает адрес ячейки, умножая индекс строки на количество элементов в ряду, и заполняет свой кэш кэш-линиями (Cache Line по 64 байта), в которые попадает сразу пачка соседних элементов этого ряда.

Когда мы обращаемся по индексу массива, процессор не загружает из медленной RAM только один элемент. Он грузит всю **Cache Line (64 байта)**, если она еще не была загружена в кэш, и это занимает ~200 тактов. Так как массив содержит данные последовательно, то **вся Cache Line в идеале — это кусок строки (ряда) многомерного массива**. Основываясь на формуле нахождения адреса `Addr = Base + (i * colls + j) * SizeOf(T)`, процессор за 1 такт вычисляет адрес, а затем за ~1-4 такта берет значение, если оно уже оказалось в кэш-линии.

>
> Вот почему Связанные Списки (Linked Lists) — это "убийцы" кэша. 
> В связанном списке каждый узел создается через malloc в случайном месте памяти. 
> Вы читаете node1. Приезжает Cache Line. Но node2 лежит в другом конце RAM! Ваша Cache Line, которую вы только что загрузили, содержит мусор.
> Для каждого узла списка процессор снова и снова ждет по 200 тактов.
>


```
Для: 
  rows = 10 ; 10 рядов  
  colls = 5 ; 5 строк 
  int matrix[rows][colls]; 

Если нужно получить значение по адресу matrix[2][3], то: 
  Addr = Base + (2 * 5 + 3) * 4

* Base: Адрес в памяти, где начинается самый первый элемент matrix[0][0]
* i (индекс строки) = 2
* colls (количество элементов в строке) = 5
* j (смещение внутри строки) = 3
* SizeOf(T) = 4 (так как тип данных — int)

```

> **Высший пилотаж оптимизации:** Если в многомерном массиве **длина строки** (количество элементов в одном ряду) будет степенью двойки (2, 4, 8, 16, 32...), то вычисление адреса становится для процессора «реактивным».
> Это следует из упрощения операции умножения на длину строки в формуле: процессор заменит её на быструю операцию сдвига `<<`.
> `Addr = Base + (i << shift) + (j << size_shift)`


**Проход по рядам (строкам). Кэш-френдли код:**

```c
int matrix[][5] = {
    {1, 2, 3, 4, 5},    
    {6, 7, 8, 9, 10},
    {11,12,13,14,15},
    ...    
};
for (int i = 0; i < 10; i++)
    for (int j = 0; j < 5; j++)
        sum += matrix[i][j]; // Мы идем подряд по памяти

// Последовательность прохода (физически в памяти):
// [1][2][3][4][5][6][7][8][9][10]... — всё берется из одной кэш-линии.

```

**Проход по столбцам (колонкам). Медленный код:**

```c
for (int j = 0; j < 5; j++)
    for (int i = 0; i < 10; i++)
        sum += matrix[i][j]; // Мы прыгаем через целые строки!

// Последовательность прохода:
// [1][6][11][2][7][12]... — каждый шаг требует новую кэш-линию.

```

Проход по столбцам может быть в 10–50 раз медленнее, потому что при каждом шаге процессор **промахивается мимо кэша** (Cache Miss). Он загрузил в кэш (L1) кусок строки (64 байта), а мы следующим шагом просим его прыгнуть на N элементов вперед, которых нет в текущей кэш-линии. Процессору приходится снова идти в медленную память (RAM), что занимает ~200–300 тактов вместо ~1–4 тактов, если бы данные были в кэше.


<details>

<summary>Попытка повлиять на поведение кеша</summary>



Что происходит:
* cache line = 64 байта = 16 int
* мы используем 1 int, а остальные 15 выбрасываются
* L1/L2 постоянно вытесняются
* prefetcher не справляется, т.к. шаг доступа = N * sizeof(int)


```c
#include <stdio.h>
#include <stdlib.h> // EXIT_SUCCESS, EXIT_FAILURE
#include <time.h>

#define N 2048

int main(void) {
    clock_t start = clock();

    static int matrix[N][N];

    // Инициализация
    for (int i = 0; i < N; i++)
        for (int j = 0; j < N; j++)
            matrix[i][j] = i + j;

    long long sum = 0;

    // ❌ ПЛОХО: обход по столбцам
    for (int j = 0; j < N; j++) {
        for (int i = 0; i < N; i++) {
            sum += matrix[i][j];
        }
    }

    clock_t end = clock();
    double cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;
    printf("%lld\n", sum);
    printf("Процессорное время: %f секунд\n", cpu_time_used);

    return EXIT_SUCCESS;
}
```

`gcc -Og -o cache_miss cache_miss.c && ./cache_miss`

Процессорное время:
* 0.056399 
* 0.057095
* 0.052826


**Есть способы влиять на поведение кеша, в том числе предварительно загружать нужные кеш-линии.**

Эти инструкции подсказывают процессору, что скоро понадобятся данные по указанному адресу, и он может загрузить их заранее, пока CPU занят другими операциями 

Альтернативы:
- prefetcht1 — для L2,
- prefetcht2 — для L3,
- prefetchnta — non-temporal prefetch (для данных, которые скоро станут ненужными — не вытесняет другие данные из кеша).

Важно: prefetch — это подсказка, а не принудительная загрузка. Процессор может её проигнорировать (например, при нехватке пропускной способности памяти).

```
int main() {
    const int N = 32;
    int data[] = {1,5,4,5,7,2,1,5,4,5,7,1,5,4,5,7,1,5,4,5,7,1,5,4,5,7,1,5,4,5,7,6};
    // Подсказать процессору: скоро понадобится data[i]
    for (int i = 0; i < N; i += 16) {
        _mm_prefetch((const char*)&data[i + 64], _MM_HINT_T0); // заглянуть вперёд на 64 байта
        // ... обработать data[i] ...
    }

// Если вы обрабатываете массив поблочно по 64 байта (размер кеш-линии), и знаете, что следующая линия понадобится через несколько тактов — делайте prefetch на 1–2 линии вперёд.
// __builtin_prefetch(&array[i + 128], 0, 3); // заглянуть на 2 шага вперёд

    return 0;
}
```


```c
int main() {
    clock_t start = clock();
    
    static int matrix[N][N];

    for (int i = 0; i < N; i++)
        for (int j = 0; j < N; j++)
            matrix[i][j] = i + j;

    long long sum = 0;

    for (int j = 0; j < N; j++) {
        for (int i = 0; i < N; i++) {

            // 🔮 явный prefetch будущей строки
            if (i + PREFETCH_DISTANCE < N) {
                _mm_prefetch(
                    (const char*)&matrix[i + PREFETCH_DISTANCE][j],
                    _MM_HINT_T0
                );
            }

            sum += matrix[i][j];
        }
    }

    clock_t end = clock();
    double cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;
    printf("%lld\n", sum);
    printf("Процессорное время: %f секунд\n", cpu_time_used);        

    return EXIT_SUCCESS;
}
```

`gcc -Og -o prefetch prefetch.c && ./prefetch`


Процессорное время, такое же как и без оптимизации: 
* 0.052012
* 0.058620

**Аппаратный prefetcher умнее, чем кажется**

Даже при доступе по столбцам современные CPU:

* распознают постоянный stride
* автоматически подтягивают линии в L2/L3

В итоге: _mm_prefetch просто дублирует работу железа

Prefetch обычно делают на сотни байт вперёд, а не на десятки, 8 итераций — это слишком мало.


</details>

---

### Cache Associativity. Уровень Кэша (Конфликт полок)

Весь RAM (гигабайты) не может влезть в маленький L1 кэш (32 КБ). Поэтому каждый адрес в памяти жестко привязан к конкретной «полке» в кэше.

Представь, что у тебя кэш L1 имеет 64 «набора». Если вы работаете с двумя огромными массивами, и их размеры — точные степени двойки (например, 4096 байт или 8192), то элементы этих массивов с одинаковыми индексами всегда будут попадать в один и тот же набор кэша.

```c
// В этом случае начало массива B находится ровно через 32768 байт (32 *\times* 1024) после начала A
// Мы выделяем память под два массива
int A[8192]; // 8192 * 4 байта = 32 KB
int B[8192]; // 32 KB

// В памяти они лежат так:
// [ --- Array A (32KB) --- ][ --- Array B (32KB) --- ]
// Адрес A[0]: 0x0000 (условно) -> Полка кэша №0
// Адрес B[0]: 0x8000 (32768)   -> Полка кэша №0 (КОНФЛИКТ!)

for (int i = 0; i < 8192; i++) {
    sum += A[i] + B[i]; 
    // На каждом шаге B[i] выбивает A[i] из кэша, 
    // а на следующем круге A[i+1] выбивает B[i]. 
    // Это Cache Thrashing. Скорость падает в разы.
}
```

Cache Aliasing (наложения в кэше) - процессор при распределении места в кеше учитывает крастность адреса массива своему размеру и если два массива совпадают по размеру и имеют один размер кратный размеру кеша то они конфликтуют за попадание в кеш, что приводит к постоянному выбрасыванию и загрузкой в кеш.
 
Трюк с «Padding», чтобы конфликта не происходило, можно специально сделать массивы чуть-чуть «неправильного» размера. Вместо `a[1024] и b[1024]` можно сделать `a[1024] и b[1024 + 1]`. Это смещает адреса так, чтобы элементы разных строк попадали на разные полки кэша, и конфликта нет.

Баланс: Потеря тактов vs Выигрыш в кэше. Если мы сделаем размер 1025 вместо 1024, мы теряем «реактивную» математику AGU (вместо сдвига `<<`  получаем долгое умножение). 

Но посмотрим на цифры:
* Потеря на математике: +2 или +3 такта на вычисление адреса
* Выигрыш на кэше: Мы избегаем похода в RAM, который стоит 200-300 тактов

Но можно еще лучше. Чтобы не выбирать между умным AGU и быстрым кэшем: 
* Оставляют длину строки равной `a[1024] и b[1024]` (степень двойки), чтобы AGU считал адрес мгновенно.
* Но между самими массивами в памяти **вставляют «прокладку» из мусорных байтов (Padding)**, чтобы их начала не были кратны размеру кэша.

```c
// Мы добавляем небольшую «мертвую зону» между массивами. 
// Нам не нужно много — достаточно сдвинуть начало второго массива на одну кэш-линию (64 байта)
// Способ 1: через структуру с "мусором"
struct {
    int A[8192];          // 32 KB
    char padding[64];     // Прокладка (64 байта мусора)
    int B[8192];          // 32 KB
} data;

// Теперь в памяти:
// [ --- Array A --- ][ 64b ] [ --- Array B --- ]
// Адрес A[0]: 0x0000 -> Полка кэша №0
// Адрес B[0]: 0x8040 -> Полка кэша №1 (ПОБЕДА!)

// Способ 2: Просто объявить массив B чуть больше, чем нужно
int A[8192];
int dummy[16]; // Резервируем 64 байта (16 * 4)
int B[8192];

```
 
 

---

Конечно, включение ассемблерного кода в программу на C делает код зависимым от определенного класса машин (например, x86-64), и поэтому его следует использовать, только когда желаемое действие можно выполнить лишь так и никак иначе.

> [!INFO]
> Ассемблер сегодня — это либо для тех, кто копается в «кишках» железа, либо для тех, кому нужно выжать последние капли скорости в математике или графике.
>
> Современные процессоры настолько сложные (конвейеры, предсказатели переходов), что человек, пытаясь «оптимизировать» код вручную, часто делает его медленнее, чем это сделал бы компилятор.
>

## Глава 4. Архитектура процессора















